{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of ML_assgn_Dataloading_sar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvesh-kale/ML-assignment-/blob/master/Copy_of_Copy_of_ML_assgn_Dataloading_sar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6XWKRmcSi0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W4b20vur4no",
        "outputId": "8b4ce271-a881-478e-eb2c-a6c28f292575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image  \n",
        "import matplotlib.pyplot as plt\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "import csv\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "import torchvision.transforms.functional as tr_F"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 84kB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMW_IY_yJCVz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu6RUV6WZBCZ"
      },
      "source": [
        "#%cd drive\n",
        "%cd My \\Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R56PIaDZ56B"
      },
      "source": [
        "**TRANFORMS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp1dX6vpJxFT"
      },
      "source": [
        "class ToTensorNormalize(object):\n",
        "    \"\"\"\n",
        "    Convert images/masks to torch.Tensor\n",
        "    Scale images' pixel values to [0-1] and normalize with predefined statistics\n",
        "    \"\"\"\n",
        "    def __call__(self, sample):\n",
        "        img = sample['image']\n",
        "        img = tr_F.to_tensor(img)\n",
        "        img = tr_F.normalize(img, mean=0.5, std=0.5)\n",
        "        sample['image'] = img\n",
        "        return sample\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZCB7f2MZ-Jq"
      },
      "source": [
        "**PREPARING INPUT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFAoXNfVLNyv"
      },
      "source": [
        "def get_file_paths(root,line): # line = line read from csv file\n",
        "        file_name='-'.join(line.split('\\\\')[-1].split('-')[0:2])\n",
        "        i_contour_name=file_name+'-icontour-manual.txt'\n",
        "        o_contour_name=file_name+'-ocontour-manual.txt'\n",
        "        image_name=file_name+'.dcm'\n",
        "\n",
        "        contour_root=root+'/'+'/'.join(line.split('\\\\')[1:3])\n",
        "        image_root=root+'/'+(line.split('\\\\')[1])+'/'+(file_name[0:3])+'dicom'\n",
        "\n",
        "        i_path=contour_root+'/'+i_contour_name\n",
        "        o_path=contour_root+'/'+o_contour_name\n",
        "        image_path=image_root+'/'+image_name\n",
        "        #print(image_path)\n",
        "        \n",
        "        return image_path,i_path,o_path\n",
        "\n",
        "class RVDataset():\n",
        "    \"\"\"\n",
        "    Base Class for RV Dataset\n",
        "\n",
        "    Args:\n",
        "        base_dir:\n",
        "            RV dataset directory\n",
        "        split:\n",
        "            which split to use\n",
        "            choose from ('train', 'val', 'trainval', 'trainaug')\n",
        "        transform:\n",
        "            transformations to be performed on images/masks\n",
        "        to_tensor:\n",
        "            transformation to convert PIL Image to tensor\n",
        "    \"\"\"\n",
        "    def __init__(self, base_dir, transforms=None, to_tensor=None):\n",
        "        \n",
        "        self.base_dir= base_dir\n",
        "        self.to_tensor = to_tensor\n",
        "        f=open(self.base_dir + \"/P_list.txt\",mode=\"r\")                                     ## Check the code syntax with example\n",
        "        self.lines=[]\n",
        "        for i, dummy in enumerate(f.readlines()):\n",
        "            if i % 2 == 0:\n",
        "                self.lines.append(dummy)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lines)\n",
        " \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Fetch data\n",
        "\n",
        "        line=self.lines[idx]\n",
        "        \n",
        "        image_path, epicardium_path, endocardium_path = get_file_paths(self.base_dir,line)\n",
        "        image_detail=pydicom.dcmread(image_path)                                            \n",
        "  \n",
        "        x=[]\n",
        "        y=[]\n",
        "        with open(epicardium_path,'r') as f:\n",
        "          reader = csv.reader(f,delimiter=' ')\n",
        "          reader = np.array(list(reader), dtype=float)\n",
        "        for count,line in enumerate(reader):\n",
        "          x.append(line[0])\n",
        "          y.append(line[1])\n",
        "        ic = np.transpose(np.vstack((x,y))) \n",
        "\n",
        "        x=[]\n",
        "        y=[]\n",
        "        with open(endocardium_path,'r') as f:\n",
        "          reader = csv.reader(f,delimiter=' ')\n",
        "          reader = np.array(list(reader), dtype=float)\n",
        "        for line in reader:\n",
        "          x.append(line[0])\n",
        "          y.append(line[1])        \n",
        "        oc = np.transpose(np.vstack((x,y)))\n",
        "        \n",
        "        image = image_detail.pixel_array\n",
        "        image=image.astype('uint8')\n",
        "        \n",
        "\n",
        "        image_dummy=image.copy()\n",
        "        ctr_i = np.array(ic).reshape((-1,1,2)).astype(np.int32)\n",
        "        ctr_o = np.array(oc).reshape((-1,1,2)).astype(np.int32)              \n",
        "\n",
        "        sizz = image.shape\n",
        "        image_dummy2 = np.zeros(sizz, dtype=float) \n",
        "        mask_1 =   cv2.fillPoly(image_dummy2,[ctr_i],[255,255,255])\n",
        "        mask_1 = mask_1/255\n",
        "\n",
        "        image_dummy2 = np.zeros(sizz, dtype=float ) \n",
        "        mask_2 =   cv2.fillPoly(image_dummy2,[ctr_o],[255,255,255]) \n",
        "        mask_2 = mask_2/255\n",
        "        \n",
        "        if(image.shape == (256,216)):\n",
        "          image = np.transpose(image)\n",
        "          mask_1 = np.transpose(mask_1)\n",
        "          mask_2 = np.transpose(mask_2)\n",
        "\n",
        "\n",
        "        mask_1 = torch.Tensor(np.array(mask_1))   #long()   \n",
        "        mask_2 = torch.Tensor(np.array(mask_2))   #long()\n",
        "        target = torch.stack ((mask_1, mask_2),dim=0)\n",
        "\n",
        "\n",
        "        sample = {'image': image,\n",
        "                  'target': target\n",
        "                  }\n",
        "\n",
        "        # Transform to tensor\n",
        "        if self.to_tensor is not None:\n",
        "            sample = self.to_tensor(sample)\n",
        "\n",
        "\n",
        "        return sample['image'],sample['target']\n",
        "\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPdN7pcdaBog"
      },
      "source": [
        "**TRYING OUT INPUT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN5B-ct88clD"
      },
      "source": [
        "import math\n",
        "%cd /content/drive/My \\Drive\n",
        "dataset = RVDataset(\n",
        "        base_dir=\"/content/drive/My Drive/Training\",to_tensor=ToTensorNormalize(),)\n",
        "#creating validation and train datasets          \n",
        "batch_size = 16\n",
        "print(len(dataset))\n",
        "train_data,valid_data = random_split(dataset,[math.ceil(len(dataset)*0.9),math.floor(len(dataset)*0.1)])\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True,num_workers=8)\n",
        "val_loader = DataLoader(valid_data,batch_size=1,shuffle=True,drop_last=True,num_workers=8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv8BmA0AXmND"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "       \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j79IW6XWsBa"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "    \n",
        "    def init_weight(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m,nn.Conv2d):\n",
        "            torch.nn.init =xavier_uniform(m.weight,gain=nn.init.calculate_gain('relu'))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g188pL40ZwKC"
      },
      "source": [
        " **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qylqV2SfZLPN"
      },
      "source": [
        "loss_bce = nn.BCELoss()\n",
        "\n",
        "\n",
        "#dice loss\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        \n",
        "        return 1 - dice\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "        \n",
        "        return Dice_BCE\n",
        "\n",
        "\n",
        "#PyTorch\n",
        "ALPHA = 0.8\n",
        "GAMMA = 2\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        #first compute binary cross-entropy \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        BCE_EXP = torch.exp(-BCE)\n",
        "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
        "                       \n",
        "        return focal_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5AmHdkbaH42"
      },
      "source": [
        "**GPU Procesing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unKkA5xeYXjz"
      },
      "source": [
        "torch.cuda.is_available()\n",
        "x='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA16MS_1aPlr"
      },
      "source": [
        "**OPTIMIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51spPyr-aVkz"
      },
      "source": [
        "model = UNet(1,1) #this line corrected an error \n",
        "model=model.to(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVrk-BvAbcQb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF1_zg0yaOxb"
      },
      "source": [
        "from torch import optim\n",
        "o_adam = optim.Adam(model.parameters(),lr=0.0001,weight_decay=0.01)\n",
        "scheduler=optim.lr_scheduler.CosineAnnealingLR(o_adam, T_max=25, eta_min=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roQnDOmyaWZR"
      },
      "source": [
        "**INSTANCE OF  MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SGfYYU6ag8h"
      },
      "source": [
        "**TRAINING SCRIPT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPy96Sasagce"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zHVcjN3aY82"
      },
      "source": [
        "**ADDITIONAL TRAINING SCRIPT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ED6kzbK9mPY"
      },
      "source": [
        "%pwd\n",
        "\n",
        "model.train()\n",
        "%cd /content/drive/My \\Drive\n",
        "i_iter = 0\n",
        "\n",
        "                           \n",
        "for input,target in train_loader:\n",
        "\n",
        "    # Prepare input\n",
        "\n",
        "    input = input.view(batch_size,-1,216,256)\n",
        "    input=input.to(x)\n",
        "    tar1,tar2 = torch.split(target,[1,1],1)\n",
        "    \n",
        "    tar1=tar1.view(batch_size,-1,216,256)\n",
        "    tar2=tar2.view(batch_size,-1,216,256)\n",
        "    tar1=tar1.to(x)\n",
        "    tar2=tar2.to(x)\n",
        "    i_iter+=1\n",
        "    print(input.shape,tar1.shape)\n",
        "\n",
        "    # Forward and Backward\n",
        "\n",
        "    o_adam.zero_grad()\n",
        "    pred1 = model(input.cuda())\n",
        "    pred2 = model(input.cuda())\n",
        "    loss1 = loss_bce(pred1.cuda(),tar1.cuda())\n",
        "    loss2 = loss_bce(pred2.cuda(),tar2.cuda())\n",
        "    print(loss1,loss2)\n",
        "    loss=(loss1+loss2)/2\n",
        "    loss.backward()\n",
        "    o_adam.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if (i_iter + 1)% 5 == 0:\n",
        "        \n",
        "        torch.save(model.state_dict(),\n",
        "                  os.path.join('https://drive.google.com/drive/folders/0B3rtY00URrIuYnhfOFZKY3JZRkE?usp=sharing', 'save_weights.pth'))\n",
        "\n",
        "torch.save(model.state_dict(),\n",
        "          os.path.join('https://drive.google.com/drive/folders/0B3rtY00URrIuYnhfOFZKY3JZRkE?usp=sharing', 'save_weights.pth'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_7-7aWeWhR"
      },
      "source": [
        "model.eval()\n",
        "loss=0 \n",
        "for input,target in valid_loader:\n",
        "\n",
        "    input = target.view(batch_size,-1,216,256)\n",
        "    input=input.to(x)\n",
        "    target = target.view(batch_size,216,256)\n",
        "    target=target.to(x)\n",
        "    prediction = model(input)\n",
        "\n",
        "    loss=loss_bce(prediction,target)\n",
        "    print(loss)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9KHoWPbfHVP"
      },
      "source": [
        "# maskA,maskB = torch.split(prediction,[1,1],1)\n",
        "ta,tb = torch.split(target,[1,1],1)\n",
        "\n",
        "maskA1=(maskA>0.5).float()\n",
        "plt.imshow(ta.squeeze().detach().cpu().numpy(),cmap='gray')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(maskA1.squeeze().detach().cpu().numpy(),cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}